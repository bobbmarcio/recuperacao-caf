#!/usr/bin/env python3
"""
Script para exportar dados do MongoDB para arquivos JSON
Exporta todas as coleÃ§Ãµes CAF para facilitar migraÃ§Ã£o entre VMs
"""

import pymongo
import json
import os
from datetime import datetime
from pathlib import Path
import gzip
from typing import Dict, List
from loguru import logger

# ConfiguraÃ§Ã£o de logging
logger.add("logs/export_mongo_{time}.log", rotation="1 day")

# ConfiguraÃ§Ãµes do MongoDB
MONGODB_CONFIG = {
    'connection_string': 'mongodb://admin:admin123@localhost:27017/audit_db?authSource=admin',
    'database': 'audit_db'
}

# ColeÃ§Ãµes CAF para exportar
CAF_COLLECTIONS = [
    'caf_unidade_familiar',
    'caf_unidade_familiar_pessoa', 
    'caf_endereco',
    'caf_area_imovel',
    'caf_renda',
    'caf_funcionario_ufpr'
]

def connect_mongodb():
    """Conecta ao MongoDB"""
    try:
        client = pymongo.MongoClient(MONGODB_CONFIG['connection_string'])
        db = client[MONGODB_CONFIG['database']]
        # Testa a conexÃ£o
        client.admin.command('ping')
        logger.info(f"âœ… Conectado ao MongoDB: {MONGODB_CONFIG['database']}")
        return client, db
    except Exception as e:
        logger.error(f"âŒ Erro ao conectar ao MongoDB: {e}")
        raise

def export_collection_to_json(db, collection_name: str, output_dir: Path) -> Dict:
    """Exporta uma coleÃ§Ã£o para arquivo JSON comprimido"""
    logger.info(f"ğŸ“¤ Exportando coleÃ§Ã£o: {collection_name}")
    
    try:
        collection = db[collection_name]
        
        # Conta documentos
        total_docs = collection.count_documents({})
        logger.info(f"ğŸ“Š Total de documentos: {total_docs:,}")
        
        if total_docs == 0:
            logger.warning(f"âš ï¸ ColeÃ§Ã£o {collection_name} estÃ¡ vazia")
            return {"collection": collection_name, "documents": 0, "file": None}
        
        # Nome do arquivo
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{collection_name}_{timestamp}.json.gz"
        filepath = output_dir / filename
        
        # Exporta documentos em lotes
        batch_size = 1000
        exported_count = 0
        
        with gzip.open(filepath, 'wt', encoding='utf-8') as f:
            f.write('[\n')
            first_doc = True
            
            for doc in collection.find().batch_size(batch_size):
                # Remove o _id do MongoDB (serÃ¡ regenerado na importaÃ§Ã£o)
                if '_id' in doc:
                    del doc['_id']
                
                # Adiciona vÃ­rgula entre documentos (exceto o primeiro)
                if not first_doc:
                    f.write(',\n')
                else:
                    first_doc = False
                
                # Escreve o documento
                json.dump(doc, f, ensure_ascii=False, default=str)
                exported_count += 1
                
                # Log de progresso
                if exported_count % 10000 == 0:
                    logger.info(f"ğŸ“ Exportados {exported_count:,} documentos...")
            
            f.write('\n]')
        
        # Verifica o tamanho do arquivo
        file_size_mb = filepath.stat().st_size / (1024 * 1024)
        
        logger.success(f"âœ… ExportaÃ§Ã£o concluÃ­da: {collection_name}")
        logger.info(f"ğŸ“ Arquivo: {filename}")
        logger.info(f"ğŸ“Š Documentos exportados: {exported_count:,}")
        logger.info(f"ğŸ’¾ Tamanho do arquivo: {file_size_mb:.2f} MB")
        
        return {
            "collection": collection_name,
            "documents": exported_count,
            "file": filename,
            "size_mb": file_size_mb
        }
        
    except Exception as e:
        logger.error(f"âŒ Erro ao exportar {collection_name}: {e}")
        return {"collection": collection_name, "error": str(e)}

def create_metadata_file(exports: List[Dict], output_dir: Path):
    """Cria arquivo de metadados da exportaÃ§Ã£o"""
    timestamp = datetime.now().isoformat()
    
    metadata = {
        "export_timestamp": timestamp,
        "total_collections": len(exports),
        "mongodb_config": {
            "database": MONGODB_CONFIG['database']
        },
        "collections": exports,
        "summary": {
            "total_documents": sum(exp.get("documents", 0) for exp in exports),
            "total_size_mb": sum(exp.get("size_mb", 0) for exp in exports),
            "successful_exports": len([exp for exp in exports if "error" not in exp]),
            "failed_exports": len([exp for exp in exports if "error" in exp])
        }
    }
    
    metadata_file = output_dir / f"export_metadata_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    
    with open(metadata_file, 'w', encoding='utf-8') as f:
        json.dump(metadata, f, indent=2, ensure_ascii=False, default=str)
    
    logger.info(f"ğŸ“‹ Metadados salvos: {metadata_file.name}")
    return metadata

def main():
    """FunÃ§Ã£o principal de exportaÃ§Ã£o"""
    print("ğŸš€ EXPORTAÃ‡ÃƒO DE DADOS MONGODB CAF")
    print("=" * 50)
    
    # Cria diretÃ³rio de saÃ­da
    output_dir = Path("export_mongodb")
    output_dir.mkdir(exist_ok=True)
    
    logger.info(f"ğŸ“‚ DiretÃ³rio de saÃ­da: {output_dir.absolute()}")
    
    try:
        # Conecta ao MongoDB
        client, db = connect_mongodb()
        
        # Lista coleÃ§Ãµes disponÃ­veis
        available_collections = db.list_collection_names()
        logger.info(f"ğŸ“‹ ColeÃ§Ãµes disponÃ­veis: {len(available_collections)}")
        
        # Verifica quais coleÃ§Ãµes CAF existem
        existing_caf_collections = [col for col in CAF_COLLECTIONS if col in available_collections]
        missing_collections = [col for col in CAF_COLLECTIONS if col not in available_collections]
        
        if missing_collections:
            logger.warning(f"âš ï¸ ColeÃ§Ãµes nÃ£o encontradas: {missing_collections}")
        
        logger.info(f"âœ… ColeÃ§Ãµes CAF encontradas: {len(existing_caf_collections)}")
        
        # Exporta cada coleÃ§Ã£o
        exports = []
        for collection_name in existing_caf_collections:
            export_result = export_collection_to_json(db, collection_name, output_dir)
            exports.append(export_result)
            print(f"âœ… {collection_name}: {export_result.get('documents', 0):,} documentos")
        
        # Cria arquivo de metadados
        metadata = create_metadata_file(exports, output_dir)
        
        # RelatÃ³rio final
        print("\nğŸ“Š RELATÃ“RIO DE EXPORTAÃ‡ÃƒO")
        print("=" * 50)
        print(f"ğŸ“‚ DiretÃ³rio: {output_dir.absolute()}")
        print(f"ğŸ—ƒï¸ ColeÃ§Ãµes exportadas: {metadata['summary']['successful_exports']}")
        print(f"ğŸ“„ Total de documentos: {metadata['summary']['total_documents']:,}")
        print(f"ğŸ’¾ Tamanho total: {metadata['summary']['total_size_mb']:.2f} MB")
        
        if metadata['summary']['failed_exports'] > 0:
            print(f"âŒ Falhas: {metadata['summary']['failed_exports']}")
        
        print(f"\nğŸ‰ ExportaÃ§Ã£o concluÃ­da!")
        print(f"ğŸ“‹ Metadados: export_metadata_*.json")
        print(f"ğŸ“¦ Arquivos: *.json.gz")
        
        # Fecha conexÃ£o
        client.close()
        
    except Exception as e:
        logger.error(f"ğŸ’¥ Erro na exportaÃ§Ã£o: {e}")
        print(f"âŒ Erro: {e}")
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main())
